#  Comparaci贸n de Modelos Boosting en Machine Learning

Este proyecto presenta una comparaci贸n entre tres algoritmos de ensamble secuencial: **AdaBoost**, **Gradient Boosting** y **XGBoost**, aplicados a un problema de clasificaci贸n binaria. Se entrena cada modelo con hiperpar谩metros por defecto y luego se realiza una b煤squeda de hiperpar谩metros para mejorar su rendimiento.

---

##  Contenido

- Preprocesamiento de datos
- Entrenamiento de modelos (default y tuned)
- Evaluaci贸n con m茅tricas:
  - Accuracy
  - F1-Score
  - AUC (rea bajo la curva ROC)
- Curvas ROC para cada modelo
- Comparaci贸n visual de resultados
- Conclusiones

---

##  Tecnolog铆as utilizadas

- Python 3.x
- Pandas
- Scikit-learn
- XGBoost
- Matplotlib / Seaborn

---

##  Resultados Finales

| Modelo             | Accuracy | F1-Score | AUC   |
|--------------------|----------|----------|--------|
| AdaBoost (tuned)         | 0.8059   | 0.8083   | 0.8907 |
| Gradient Boosting (tuned)| 0.8017   | 0.8000   | 0.8928 |
| XGBoost (tuned)          | 0.8017   | 0.7983   | 0.8879 |

> **Conclusi贸n**: Todos los modelos mejoraron su desempe帽o tras el ajuste de hiperpar谩metros, siendo Gradient Boosting el que obtuvo el mejor AUC general.

---

##  C贸mo usar este proyecto

1. Clona este repositorio:
   ```bash
   git clone https://github.com/tuusuario/nombre-del-repo.git
